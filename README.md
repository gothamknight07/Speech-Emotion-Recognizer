# Speech-Emotion-Recognizer
The goal of this projectÂ was to build a machine learning model that could recognize emotions from the speech we constantly exchange with one another.

It is another advanced-level ML project where we have to deal mostly with audio data. Speech emotion recognition attempts to identify and interpret user emotions and deduce the emotional state from speech. To train such an algorithm, we have to use most of the training data as audio data. This system will take user speech as input. Apart from general Python libraries like NumPy, Pyaudio, and Soundfile, this project will also utilize Librosa. Librosa is a Python library that helps analyze audio data and music files. We also need Scikit-Learn to build the project model implementing the MLPClassifier (Multi-layer Perceptron classifier). You can use the JupyterLab web-based UI to develop this project. 

This project requires the RAVDESS dataset to train the machine learning model with different audio. The RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song) dataset contains 7356 files with voice samples of 24 professional actors (12 females and 12 males). It comprises different speech intensities like happy, calm, angry, sad, surprise, fearful, and disgust expressions, along with songs with diverse emotions like sad, happy, frightful, peaceful, and fierce.


